# Linear Regression From Scratch

This project focuses on implementing **Linear Regression from scratch**
without using machine learning libraries such as scikit-learn.

The goal is to deeply understand how linear regression works internally,
including the mathematics and optimization process.

---

## ðŸ“Œ What This Project Covers

- Linear regression theory and intuition
- Cost function (Mean Squared Error)
- Gradient Descent optimization
- Manual weight and bias updates
- Model convergence and learning rate impact

---

## ðŸ§  Approach

The model is implemented step by step using:
- Python
- NumPy (for numerical computations)

Instead of relying on high-level ML libraries, the algorithm logic is written
manually to strengthen conceptual understanding.

---

## ðŸ“‚ Files

- `Linear_Regression_Gradient_Descent.ipynb`  
  Notebook implementing linear regression using gradient descent from scratch.

---

## ðŸŽ¯ Learning Outcome

By completing this project, I gained:
- A strong understanding of gradient descent
- Insight into how loss minimization works
- Confidence to implement ML algorithms from first principles

This project builds a solid foundation for more advanced regression techniques.